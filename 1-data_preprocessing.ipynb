{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from lime import lime_tabular\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, target_column, categorical_columns=[], n_train=None):\n",
    "    # Remove rows where target contains NaN values\n",
    "    df = df.dropna(subset=[target_column])\n",
    "    \n",
    "    # Frequency encoding for categorical features\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "    # Split the dataset into features (X) and target (y)\n",
    "    X = df.drop(target_column, axis=1)  # Features\n",
    "    y = df[target_column]  # Target\n",
    "\n",
    "    # Get number of features (p) and total samples (n_total)\n",
    "    p = X.shape[1]\n",
    "    n_total = X.shape[0]\n",
    "\n",
    "    # Train-test split\n",
    "    if n_train:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=n_train, random_state=42)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, n_total, p, X.columns.tolist()  # Return feature names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st dataset- Parkinson's Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinsons_df = pd.read_csv('data/parkinsons.data')\n",
    "parkinsons_df = parkinsons_df.drop('name', axis=1)\n",
    "target_column = 'status'\n",
    "categorical_columns = []\n",
    "X_train_parkinsons, X_test_parkinsons, y_train_parkinsons, y_test_parkinsons, n_total_parkinsons, p_parkinsons, feature_names_parkinsons = preprocess_data(parkinsons_df, 'status', [], n_train=175)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>0.426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>0.626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>0.482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>0.584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
       "0      119.992       157.302        74.997         0.00784           0.00007   \n",
       "1      122.400       148.650       113.819         0.00968           0.00008   \n",
       "2      116.682       131.111       111.555         0.01050           0.00009   \n",
       "3      116.676       137.871       111.366         0.00997           0.00009   \n",
       "4      116.014       141.781       110.655         0.01284           0.00011   \n",
       "\n",
       "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \\\n",
       "0   0.00370   0.00554     0.01109       0.04374             0.426  ...   \n",
       "1   0.00465   0.00696     0.01394       0.06134             0.626  ...   \n",
       "2   0.00544   0.00781     0.01633       0.05233             0.482  ...   \n",
       "3   0.00502   0.00698     0.01505       0.05492             0.517  ...   \n",
       "4   0.00655   0.00908     0.01966       0.06425             0.584  ...   \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parkinsons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the 'status' column: [1 0]\n"
     ]
    }
   ],
   "source": [
    "unique_values = parkinsons_df['status'].unique()\n",
    "\n",
    "# Print unique values\n",
    "print(\"Unique values in the 'status' column:\", unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessed data into a DataFrame\n",
    "parkinsons_train = pd.DataFrame(X_train_parkinsons)\n",
    "parkinsons_train['status'] = y_train_parkinsons\n",
    "parkinsons_test = pd.DataFrame(X_test_parkinsons)\n",
    "parkinsons_test['status'] = y_test_parkinsons\n",
    "\n",
    "# Save preprocessed Parkinson's data as CSV\n",
    "parkinsons_train.to_csv('preprocessed_data/parkinsons_train.csv', index=False)\n",
    "parkinsons_test.to_csv('preprocessed_data/parkinsons_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd Dataset- Breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df = pd.read_csv('data/cancer.csv')\n",
    "cancer_df = cancer_df.drop(['id', 'Unnamed: 32'], axis=1)\n",
    "cancer_df['diagnosis'] = cancer_df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "target_column = 'diagnosis'\n",
    "# Updated unpacking for the Cancer dataset\n",
    "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer, n_total_cancer, p_cancer, feature_names_cancer = preprocess_data(cancer_df, 'diagnosis', [], n_train=512)\n",
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the 'diagnosis' column: [1 0]\n"
     ]
    }
   ],
   "source": [
    "unique_values = cancer_df['diagnosis'].unique()\n",
    "\n",
    "# Print unique values\n",
    "print(\"Unique values in the 'diagnosis' column:\", unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessed data into a DataFrame\n",
    "cancer_train = pd.DataFrame(X_train_cancer)\n",
    "cancer_train['diagnosis'] = y_train_cancer\n",
    "cancer_test = pd.DataFrame(X_test_cancer)\n",
    "cancer_test['diagnosis'] = y_test_cancer\n",
    "\n",
    "# Save preprocessed Cancer data as CSV\n",
    "cancer_train.to_csv('preprocessed_data/cancer_train.csv', index=False)\n",
    "cancer_test.to_csv('preprocessed_data/cancer_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd Dataset - Adult Income Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>216864</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3770</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>150601</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>3770</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "5   34   Private  216864       HS-grad              9       Divorced   \n",
       "6   38   Private  150601          10th              6      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "5      Other-service      Unmarried  White  Female             0   \n",
       "6       Adm-clerical      Unmarried  White    Male             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country  income  \n",
       "1          4356              18  United-States       0  \n",
       "3          3900              40  United-States       0  \n",
       "4          3900              40  United-States       0  \n",
       "5          3770              45  United-States       0  \n",
       "6          3770              40  United-States       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_df = pd.read_csv('data/adult.csv')\n",
    "adult_df = adult_df.replace('?', np.nan)  # Handle missing values\n",
    "adult_df = adult_df.dropna()  # Drop any rows with missing values\n",
    "categorical_columns = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']\n",
    "target_column = 'income'\n",
    "adult_df[target_column] = adult_df[target_column].map({'<=50K': 0, '>50K': 1})\n",
    "adult_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the 'income' column: [0 1]\n"
     ]
    }
   ],
   "source": [
    "unique_values = adult_df['income'].unique()\n",
    "\n",
    "# Print unique values\n",
    "print(\"Unique values in the 'income' column:\", unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_adult, X_test_adult, y_train_adult, y_test_adult, n_total_adult, p_adult, feature_names_adult = preprocess_data(adult_df, target_column, categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessed data into a DataFrame\n",
    "adult_train = pd.DataFrame(X_train_adult)\n",
    "adult_train['income'] = y_train_adult\n",
    "adult_test = pd.DataFrame(X_test_adult)\n",
    "adult_test['income'] = y_test_adult\n",
    "\n",
    "# Save preprocessed Adult data as CSV\n",
    "adult_train.to_csv('preprocessed_data/adult_train.csv', index=False)\n",
    "adult_test.to_csv('preprocessed_data/adult_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4th Dataset- Boston dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = fetch_openml(name=\"boston\", version=1, as_frame=True)\n",
    "X, y = boston.data, boston.target\n",
    "boston_df = X.copy()\n",
    "boston_df['MEDV'] = y  # MEDV is the house price (target)\n",
    "target_column = 'MEDV'\n",
    "categorical_columns = []\n",
    "X_train_boston, X_test_boston, y_train_boston, y_test_boston, n_total_boston, p_boston, feature_names_boston = preprocess_data(boston_df, 'MEDV', [], n_train=455)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS CHAS    NOX     RM   AGE     DIS RAD    TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31    0  0.538  6.575  65.2  4.0900   1  296.0     15.3   \n",
       "1  0.02731   0.0   7.07    0  0.469  6.421  78.9  4.9671   2  242.0     17.8   \n",
       "2  0.02729   0.0   7.07    0  0.469  7.185  61.1  4.9671   2  242.0     17.8   \n",
       "3  0.03237   0.0   2.18    0  0.458  6.998  45.8  6.0622   3  222.0     18.7   \n",
       "4  0.06905   0.0   2.18    0  0.458  7.147  54.2  6.0622   3  222.0     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the 'MEDV' column: [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  21.7 20.4 18.2\n",
      " 19.9 23.1 17.5 20.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8 18.4 21.\n",
      " 12.7 13.2 13.1 13.5 20.  24.7 30.8 34.9 26.6 25.3 21.2 19.3 14.4 19.4\n",
      " 19.7 20.5 25.  23.4 35.4 31.6 23.3 18.7 16.  22.2 33.  23.5 22.  17.4\n",
      " 20.9 24.2 22.8 24.1 21.4 20.8 20.3 28.  23.9 24.8 22.5 23.6 22.6 20.6\n",
      " 28.4 38.7 43.8 33.2 27.5 26.5 18.6 20.1 19.5 19.8 18.8 18.5 18.3 19.2\n",
      " 17.3 15.7 16.2 18.  14.3 23.  18.1 17.1 13.3 17.8 14.  13.4 11.8 13.8\n",
      " 14.6 15.4 21.5 15.3 17.  41.3 24.3 27.  50.  22.7 23.8 22.3 19.1 29.4\n",
      " 23.2 24.6 29.9 37.2 39.8 37.9 32.5 26.4 29.6 32.  29.8 37.  30.5 36.4\n",
      " 31.1 29.1 33.3 30.3 34.6 32.9 42.3 48.5 24.4 22.4 28.1 23.7 26.7 30.1\n",
      " 44.8 37.6 46.7 31.5 31.7 41.7 48.3 29.  25.1 17.6 24.5 26.2 42.8 21.9\n",
      " 44.  36.  33.8 43.1 48.8 31.  36.5 30.7 43.5 20.7 21.1 25.2 35.2 32.4\n",
      " 33.1 35.1 45.4 46.  32.2 28.5 37.3 27.9 28.6 36.1 28.2 16.1 22.1 19.\n",
      " 32.7 31.2 17.2 16.8 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 11.5\n",
      " 15.1  9.7 12.5  8.5  5.   6.3  5.6 12.1  8.3 11.9 17.9 16.3  7.   7.5\n",
      "  8.4 16.7 14.2 11.7 11.   9.5 14.1  9.6  8.7 12.8 10.8 14.9 12.6 13.\n",
      " 16.4 17.7 12.  21.8  8.1]\n"
     ]
    }
   ],
   "source": [
    "unique_values = boston_df['MEDV'].unique()\n",
    "\n",
    "# Print unique values\n",
    "print(\"Unique values in the 'MEDV' column:\", unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessed data into a DataFrame\n",
    "boston_train = pd.DataFrame(X_train_boston)\n",
    "boston_train['MEDV'] = y_train_boston\n",
    "boston_test = pd.DataFrame(X_test_boston)\n",
    "boston_test['MEDV'] = y_test_boston\n",
    "\n",
    "# Save preprocessed Boston data as CSV\n",
    "boston_train.to_csv('preprocessed_data/boston_train.csv', index=False)\n",
    "boston_test.to_csv('preprocessed_data/boston_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5th Dataset- Body fat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodyfat_df = pd.read_csv('data/bodyfat.csv')\n",
    "target_column = 'BodyFat'\n",
    "X_train_bodyfat, X_test_bodyfat, y_train_bodyfat, y_test_bodyfat, n_total_bodyfat, p_bodyfat, feature_names_bodyfat = preprocess_data(bodyfat_df, 'BodyFat', [], n_train=226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessed data into a DataFrame\n",
    "bodyfat_train = pd.DataFrame(X_train_bodyfat)\n",
    "bodyfat_train['BodyFat'] = y_train_bodyfat\n",
    "bodyfat_test = pd.DataFrame(X_test_bodyfat)\n",
    "bodyfat_test['BodyFat'] = y_test_bodyfat\n",
    "\n",
    "# Save preprocessed Body Fat data as CSV\n",
    "bodyfat_train.to_csv('preprocessed_data/bodyfat_train.csv', index=False)\n",
    "bodyfat_test.to_csv('preprocessed_data/bodyfat_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>BodyFat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.513635</td>\n",
       "      <td>-0.325662</td>\n",
       "      <td>1.800997</td>\n",
       "      <td>1.092458</td>\n",
       "      <td>1.588329</td>\n",
       "      <td>1.956956</td>\n",
       "      <td>1.509134</td>\n",
       "      <td>1.199663</td>\n",
       "      <td>1.543193</td>\n",
       "      <td>1.122745</td>\n",
       "      <td>1.045447</td>\n",
       "      <td>1.642177</td>\n",
       "      <td>1.548056</td>\n",
       "      <td>1.893439</td>\n",
       "      <td>12.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.476191</td>\n",
       "      <td>0.633290</td>\n",
       "      <td>-0.814933</td>\n",
       "      <td>-0.231734</td>\n",
       "      <td>-0.158150</td>\n",
       "      <td>-0.797688</td>\n",
       "      <td>-0.360806</td>\n",
       "      <td>-0.743049</td>\n",
       "      <td>-1.055350</td>\n",
       "      <td>-0.963465</td>\n",
       "      <td>-0.649377</td>\n",
       "      <td>-1.228421</td>\n",
       "      <td>-1.469690</td>\n",
       "      <td>-1.203541</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.419859</td>\n",
       "      <td>-1.524352</td>\n",
       "      <td>0.246483</td>\n",
       "      <td>1.158668</td>\n",
       "      <td>0.207392</td>\n",
       "      <td>0.089401</td>\n",
       "      <td>-0.823752</td>\n",
       "      <td>-0.240389</td>\n",
       "      <td>0.058311</td>\n",
       "      <td>0.468248</td>\n",
       "      <td>1.359303</td>\n",
       "      <td>0.190380</td>\n",
       "      <td>0.360746</td>\n",
       "      <td>0.291553</td>\n",
       "      <td>25.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.701851</td>\n",
       "      <td>-0.964963</td>\n",
       "      <td>0.179622</td>\n",
       "      <td>-0.364153</td>\n",
       "      <td>1.100939</td>\n",
       "      <td>-0.214077</td>\n",
       "      <td>-0.052175</td>\n",
       "      <td>0.479637</td>\n",
       "      <td>0.856435</td>\n",
       "      <td>-0.513498</td>\n",
       "      <td>0.292192</td>\n",
       "      <td>0.421348</td>\n",
       "      <td>0.954401</td>\n",
       "      <td>1.573062</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.672622</td>\n",
       "      <td>-0.405574</td>\n",
       "      <td>-0.071106</td>\n",
       "      <td>0.231734</td>\n",
       "      <td>-0.239382</td>\n",
       "      <td>-0.249093</td>\n",
       "      <td>0.038599</td>\n",
       "      <td>0.221514</td>\n",
       "      <td>-0.053055</td>\n",
       "      <td>0.427342</td>\n",
       "      <td>-0.900462</td>\n",
       "      <td>-0.469527</td>\n",
       "      <td>-0.381323</td>\n",
       "      <td>-1.737503</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.513635 -0.325662  1.800997  1.092458  1.588329  1.956956  1.509134   \n",
       "1  0.476191  0.633290 -0.814933 -0.231734 -0.158150 -0.797688 -0.360806   \n",
       "2  1.419859 -1.524352  0.246483  1.158668  0.207392  0.089401 -0.823752   \n",
       "3  0.701851 -0.964963  0.179622 -0.364153  1.100939 -0.214077 -0.052175   \n",
       "4 -0.672622 -0.405574 -0.071106  0.231734 -0.239382 -0.249093  0.038599   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0  1.199663  1.543193  1.122745  1.045447  1.642177  1.548056  1.893439   \n",
       "1 -0.743049 -1.055350 -0.963465 -0.649377 -1.228421 -1.469690 -1.203541   \n",
       "2 -0.240389  0.058311  0.468248  1.359303  0.190380  0.360746  0.291553   \n",
       "3  0.479637  0.856435 -0.513498  0.292192  0.421348  0.954401  1.573062   \n",
       "4  0.221514 -0.053055  0.427342 -0.900462 -0.469527 -0.381323 -1.737503   \n",
       "\n",
       "   BodyFat  \n",
       "0     12.3  \n",
       "1      6.1  \n",
       "2     25.3  \n",
       "3     10.4  \n",
       "4     28.7  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bodyfat_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the 'BodyFat' column: [12.3  6.1 25.3 10.4 28.7 20.9 19.2 12.4  4.1 11.7  7.1  7.8 20.8 21.2\n",
      " 22.1 29.  22.9 16.  16.5 19.1 15.2 15.6 17.7 14.   3.7  7.9  8.8 11.9\n",
      "  5.7 11.8 21.3 32.3 40.1 24.2 28.4 35.2 32.6 34.5 32.9 31.6 32.   7.7\n",
      " 13.9 10.8  5.6 13.6  4.  10.2  6.6  8.   6.3  3.9 22.6 20.4 28.  31.5\n",
      " 24.6 26.1 29.8 30.7 25.8 30.  21.5 13.8 12.9 24.3  8.5 13.5 18.5 22.2\n",
      " 18.8 31.4 26.8 18.4 27.  26.6 14.9 23.1  8.3 14.1 20.5 18.2 24.9  9.\n",
      " 17.4  9.6 11.3 17.8 20.1 22.3 25.4 18.  19.3 18.3 17.3 21.4 19.7 26.7\n",
      " 16.7 18.1 27.9 14.7 17.5 27.2 22.7 23.6 24.4 27.1 21.8 29.4 22.4 23.3\n",
      "  9.4 10.3 14.2 29.6  5.3 25.2 19.6 10.1 21.  31.2 10.  12.5 22.5 14.6\n",
      " 13.  15.1 27.3 20.3 34.3  3.   0.7 16.9  9.9 13.1 29.9  0.  11.5 12.1\n",
      "  8.6 11.4 38.1 15.9 24.7 22.8 25.5 22.  12.2  6.  34.8 16.6 32.8 19.5\n",
      " 18.7 47.5  7.5 24.5 15.  26.   5.2 10.9 14.8 17.  10.6 16.1 15.4 18.6\n",
      " 24.8 35.  30.4 30.2 11.  33.6 29.3 31.9]\n"
     ]
    }
   ],
   "source": [
    "unique_values = bodyfat_df['BodyFat'].unique()\n",
    "\n",
    "# Print unique values\n",
    "print(\"Unique values in the 'BodyFat' column:\", unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed datasets saved successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessed datasets saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training amd Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset      Task p    n_train n_total RÂ²/Accuracy\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate classification models (SVM)\n",
    "def train_svm_classifier(X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Train and evaluate an SVM classifier.\n",
    "    :return: accuracy of the model\n",
    "    \"\"\"\n",
    "    # Train SVM classifier\n",
    "    model = SVC(kernel='linear', random_state=42, probability=True)  # Set probability=True for LIME compatibility\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Save the trained model\n",
    "    joblib.dump(model, f'models/{model_name}_svm_model.pkl')\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Train and evaluate regression models (Extra Trees Regressor)\n",
    "def train_extra_trees_regressor(X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Train and evaluate an Extra Trees Regressor.\n",
    "    :return: RÂ² score of the model\n",
    "    \"\"\"\n",
    "    # Train Extra Trees Regressor\n",
    "    model = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Save the trained model\n",
    "    joblib.dump(model, f'models/{model_name}_extra_trees_model.pkl')\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate RÂ² Score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return r2\n",
    "\n",
    "# Print table with dataset information\n",
    "def print_dataset_info(name, task_type, p, n_train, n_total, score):\n",
    "    \"\"\"\n",
    "    Print the dataset information.\n",
    "    :param name: Name of the dataset\n",
    "    :param task_type: 'C' for classification, 'R' for regression\n",
    "    :param p: Number of features\n",
    "    :param n_train: Number of training samples\n",
    "    :param n_total: Total number of samples\n",
    "    :param score: Accuracy for classification or RÂ² score for regression\n",
    "    \"\"\"\n",
    "    print(f\"{name.ljust(12)} {task_type} {str(p).ljust(4)} {str(n_train).ljust(6)} {str(n_total).ljust(7)} {score:.2f}\")\n",
    "\n",
    "# Header for the table\n",
    "print(\"Dataset      Task p    n_train n_total RÂ²/Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if not exists\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models and collect scores\n",
    "accuracy_parkinsons = train_svm_classifier(X_train_parkinsons, X_test_parkinsons, y_train_parkinsons, y_test_parkinsons, \"parkinsons\")\n",
    "accuracy_cancer = train_svm_classifier(X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer, \"cancer\")\n",
    "accuracy_adult = train_svm_classifier(X_train_adult, X_test_adult, y_train_adult, y_test_adult, \"adult\")\n",
    "r2_boston = train_extra_trees_regressor(X_train_boston, X_test_boston, y_train_boston, y_test_boston, \"boston\")\n",
    "r2_bodyfat = train_extra_trees_regressor(X_train_bodyfat, X_test_bodyfat, y_train_bodyfat, y_test_bodyfat, \"bodyfat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset   Task p    n_train n_total RÂ²/Accuracy\n",
      "Parkinson's  C 22   175    195     0.85\n",
      "Cancer       C 30   512    569     0.96\n",
      "Adult        C 14   24129  30162   0.80\n",
      "Boston       R 13   455    506     0.92\n",
      "BodyFat      R 14   226    252     1.00\n"
     ]
    }
   ],
   "source": [
    "# Print dataset info\n",
    "print(\"Dataset   Task p    n_train n_total RÂ²/Accuracy\")\n",
    "# Adjust the print statements to use shape[0] for sparse matrices\n",
    "print_dataset_info(\"Parkinson's\", 'C', p_parkinsons, X_train_parkinsons.shape[0], n_total_parkinsons, accuracy_parkinsons)\n",
    "print_dataset_info(\"Cancer\", 'C', p_cancer, X_train_cancer.shape[0], n_total_cancer, accuracy_cancer)\n",
    "print_dataset_info(\"Adult\", 'C', p_adult, X_train_adult.shape[0], n_total_adult, accuracy_adult)  # Adjusted line\n",
    "print_dataset_info(\"Boston\", 'R', p_boston, X_train_boston.shape[0], n_total_boston, r2_boston)\n",
    "print_dataset_info(\"BodyFat\", 'R', p_bodyfat, X_train_bodyfat.shape[0], n_total_bodyfat, r2_bodyfat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation RÂ² score for Body Fat: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cross_validate_extra_trees(X, y):\n",
    "    \"\"\"\n",
    "    Perform cross-validation on an Extra Trees Regressor.\n",
    "    :return: mean RÂ² score across the folds\n",
    "    \"\"\"\n",
    "    model = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Perform 5-fold cross-validation and return the mean RÂ² score\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Cross-validation for Body Fat Dataset\n",
    "cross_val_score_bodyfat = cross_validate_extra_trees(X_train_bodyfat, y_train_bodyfat)\n",
    "print(f\"Cross-validation RÂ² score for Body Fat: {cross_val_score_bodyfat:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset   Task p    n_train n_total RÂ²/Accuracy\n",
      "Parkinson's  C 22   175    195     0.85\n",
      "Cancer       C 30   512    569     0.96\n",
      "Adult        C 14   24129  30162   0.80\n",
      "Boston       R 13   455    506     0.92\n",
      "BodyFat      R 14   226    252     1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset   Task p    n_train n_total RÂ²/Accuracy\")\n",
    "# Using shape[0] for sparse matrices to get the number of samples\n",
    "print_dataset_info(\"Parkinson's\", 'C', p_parkinsons, X_train_parkinsons.shape[0], n_total_parkinsons, accuracy_parkinsons)\n",
    "print_dataset_info(\"Cancer\", 'C', p_cancer, X_train_cancer.shape[0], n_total_cancer, accuracy_cancer)\n",
    "print_dataset_info(\"Adult\", 'C', p_adult, X_train_adult.shape[0], n_total_adult, accuracy_adult)  # Adjusted line\n",
    "print_dataset_info(\"Boston\", 'R', p_boston, X_train_boston.shape[0], n_total_boston, r2_boston)\n",
    "print_dataset_info(\"BodyFat\", 'R', p_bodyfat, X_train_bodyfat.shape[0], n_total_bodyfat, r2_bodyfat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
